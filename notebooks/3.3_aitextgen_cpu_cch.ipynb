{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI TEXT GENERATION FOR BEGINNERS: CREATING AND FINE TUNING YOUR OWN SINGLISH CHATBOT\n",
    "\n",
    "# PART 4: ALTERNATIVE USING CPU\n",
    "\n",
    "If you are just starting out in NLP/data science, it is likely that you wouldn't want to spend money on Colab Pro + additonal storage before you are sure this is something you would be doing a lot more of in the future. Thankfully there are CPU-based alternatives if you are merely dipping your toes into this area.\n",
    "\n",
    "I'll just highlight one that I've been trying out - [aitextgen](https://github.com/minimaxir/aitextgen) by Max Woolf.\n",
    "\n",
    "The code below is lifted from the demo on his Github repo. This notebook ran for about 2 hours on a 2018 Mac Mini (64Gb RAM), but you can dial down the training parameters for a faster iteration. The results weren't as satisfactory as the ones from fine tuning DialoGPT-medium, but I reckon it's not a fair comparison.\n",
    "\n",
    "But if you are keen to try aitextgen on Colab, here's another [demo notebook](https://colab.research.google.com/drive/144MdX5aLqrQ3-YW-po81CQMrD6kpgpYh) you can try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the time of writing, aitextgen doesn't work with transformers > v3.0.0\n",
    "# check the version on your local machine if there's a conflict\n",
    "\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was created at the end of notebook 1.0\n",
    "\n",
    "file_name = \"../data/singlish_sms.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a custom BPE Tokenizer\n",
    "# This will save two files: aitextgen-vocab.json and aitextgen-merges.txt, which are needed to rebuild the tokenizer.\n",
    "\n",
    "train_tokenizer(file_name)\n",
    "vocab_file = \"aitextgen-vocab.json\"\n",
    "merges_file = \"aitextgen-merges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2ConfigCPU is a mini variant of GPT-2 optimized for CPU-training\n",
    "# e.g. the # of input tokens here is 64 vs. 1024 for base GPT-2\n",
    "\n",
    "config = GPT2ConfigCPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate aitextgen using the created tokenizer and config\n",
    "ai = aitextgen(vocab_file=vocab_file, merges_file=merges_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can build datasets for training by creating TokenDatasets,\n",
    "# which automatically processes the dataset with the appropriate size.\n",
    "\n",
    "data = TokenDataset(\n",
    "    file_name,\n",
    "    vocab_file=vocab_file,\n",
    "    merges_file=merges_file,\n",
    "    block_size=64,\n",
    "    num_workers=12,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.train(\n",
    "    data,\n",
    "    batch_size=32,\n",
    "    num_steps=20000,\n",
    "    num_workers=12,\n",
    "    learning_rate=1e-5,\n",
    "    generate_every=10000,\n",
    "    save_every=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample training text you can expect to see:\n",
    "\n",
    "10,000 steps reached: saving model to /trained_model\n",
    "10,000 steps reached: generating sample texts.\n",
    "\n",
    "==========\n",
    "', 'Haha s my not so I know 'I just m in the the the best Haha', 'Haha what s the lot', 'Haha oh Haha I think we think t go my way time I m s the not I no I want to see I have to make me and it s I can be',\n",
    "==========\n",
    "\n",
    "20,000 steps reached: saving model to /trained_model\n",
    "20,000 steps reached: generating sample texts.\n",
    "==========\n",
    " slp', 'Hahaha okay it s really just be out for the last one haha I just know I m m at the house', 'Eh I m sure', 'Haha no no you want that s', 'Haha okay how to do you all', 'Haha but I m not not free', 'Haha no also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.generate(n=5, max_length=15, prompt=\"eh how ah\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
